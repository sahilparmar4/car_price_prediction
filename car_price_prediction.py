# -*- coding: utf-8 -*-
"""car_price_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FI_ryqi1NcHVll1gEOJsv2jKg68XmZP0
"""

import numpy as np
import pandas as pd

df = pd.read_csv("/content/drive/MyDrive/Goeduhub/car data.csv")
df.head()

df.isnull().sum()

df.shape

df.info()

df.describe()

df.corr()

df.columns

df["Fuel_Type"].unique()

df["Seller_Type"].unique()

df = df.drop(["Car_Name"], axis = 1)
df.head()

df["current_year"] = 2021
df.head()

df["no_of_years"] = df["current_year"] - df["Year"]
df.head()

df = df.drop(["Year"], axis = 1)
df.head()

df = pd.get_dummies(df, drop_first = True)
df.head()

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sb
import matplotlib.pyplot as plt
# %matplotlib inline
plt.figure(figsize = (10, 10))
sb.heatmap(df.corr(), annot = True)

x = df.iloc[:, 1:]
y = df.iloc[:, 0]

import sklearn
from sklearn.model_selection import train_test_split

xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.25, random_state = 4)

df.to_csv("test.csv")

from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor()

regressor.fit(xtrain, ytrain)

ypred = regressor.predict(xtest)
ypred

from sklearn.ensemble import ExtraTreesRegressor

model = ExtraTreesRegressor()
model.fit(x, y)
print(model.feature_importances_)

feature_importance = pd.Series(model.feature_importances_, index = x.columns)
feature_importance.nlargest(5).plot(kind = "bar")

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=0)

from sklearn.linear_model import LinearRegression
reg=LinearRegression()
reg.fit(xtrain, ytrain)
ypred = reg.predict(xtest)
from sklearn import metrics
print('MAE:', metrics.mean_absolute_error(ytest, ypred))
print('MSE:', metrics.mean_squared_error(ytest, ypred))
print('RMSE:', np.sqrt(metrics.mean_squared_error(ytest, ypred)))
R2 = metrics.r2_score(ytest,ypred)
print('R2:',R2)

n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]
print(n_estimators)

from sklearn.model_selection import RandomizedSearchCV
n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]
min_samples_split = [2, 5, 10, 15, 100]
min_samples_leaf = [1, 2, 5, 10]

random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf}

print(random_grid)

rf = RandomForestRegressor()

rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 1)

rf_random.fit(xtrain,ytrain)

rf_random.best_params_

rf_random.best_score_

ypred=rf_random.predict(xtest)
print('MAE:', metrics.mean_absolute_error(ytest, ypred))
print('MSE:', metrics.mean_squared_error(ytest, ypred))
print('RMSE:', np.sqrt(metrics.mean_squared_error(ytest, ypred)))
R2 = metrics.r2_score(ytest,ypred)
print('R2:',R2)

import pickle
file = open('car_price_model.pkl', 'wb')

pickle.dump(rf_random, file)